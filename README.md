# Teleop Navigation Options

## Hardware

* [ROS Bot](https://www.rosbots.com)
* [TurtleBot3](http://www.robotis.us/turtlebot-3/)
* [Magni Robot](https://ubiquityrobotics.com)

## Software

* [Google Speech API](https://cloud.google.com/speech/). 

* [Google Vision API](https://cloud.google.com/vision/). Same exercise as speech, but
using pictures to control a robot.

* OCR using [Google Vision API](https://hackernoon.com/optical-character-recognition-with-google-cloud-vision-api-255bb8241235)

* [Facial expressions](https://azure.microsoft.com/en-us/services/cognitive-services/emotion/)

* [Twilio](https://www.twilio.com) to enable control via voice or sms.

* OpenCV to recognize a colored object moving in a particular direction.
The object can either be hand held or it can be an object like a 
[gold fish](http://www.bbc.com/news/av/technology-27241688/smart-tank-time-to-take-the-fish-for-a-walk).

* [Flutter.io](https://flutter.io) and/or web page via a REST API

## Devices

* [Google AIY Vision Kit](https://aiyprojects.withgoogle.com/vision/)

* [Myo](https://www.myo.com/) control

* [LEAP motion controller](https://www.leapmotion.com)

* Train [Amazon Alexa](https://developer.amazon.com/docs/custom-skills/steps-to-build-a-custom-skill.html) 
to understand movement commands

* Hand-held [IMU](https://www.adafruit.com/product/2472) 

* 360 degree lidar to interpret hand angles and distances.

* Build a glove with [these](https://www.adafruit.com/product/182) embedded and sense finger curls.
