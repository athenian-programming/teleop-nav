# Teleop Navigation Options

## Hardware

* [ROS Bot](https://www.rosbots.com)
* [Magni Robot](https://ubiquityrobotics.com)
* [TurtleBot3](http://www.robotis.us/turtlebot-3/)


## Software

* [Google Speech API](https://cloud.google.com/speech/). 

* [Google vision API](https://cloud.google.com/vision/). Same exercise as speech, but
using pictures to control a robot.

* OCR using Google Vision API (https://hackernoon.com/optical-character-recognition-with-google-cloud-vision-api-255bb8241235)

* Slack chat bot. APIs that we could use include:
https://api.ai and https://recast.ai Both make building a bot and processing natural language really easy.

* [Twilio](https://www.twilio.com) to enable control via voice or sms.

* Face expressions (https://azure.microsoft.com/en-us/services/cognitive-services/emotion/)

* OpenCV to recognize a colored object moving in a particular direction.
The object can either be hand held or it can be an object like a 
gold fish (http://www.bbc.com/news/av/technology-27241688/smart-tank-time-to-take-the-fish-for-a-walk)

* [Flutter.io](https://flutter.io) and/or web page via a REST API

## Devices

* [Adafruit Bonnet](https://www.adafruit.com/product/4085)

* [Google AIY Vision KitV](https://aiyprojects.withgoogle.com/vision/)

* [Myo](https://www.myo.com/) control

* [LEAP motion controller](https://www.leapmotion.com)

* Train Amazon Alexa to understand movement commands

* IMU 

* 360 degree lidar to interpret hand angles and distances.

* Build a glove with [these](https://www.adafruit.com/product/182) embedded and sense finger curls.
